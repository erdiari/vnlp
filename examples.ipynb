{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Morphological Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[dynet] random seed: 1830085866\n",
      "[dynet] allocating memory: 512MB\n",
      "[dynet] memory allocation done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-07 22:19:45,407 - /Users/meliksahturker/Desktop/Turkish-NLP-preprocessing-module/pp/morph_analyzer/model.py - INFO - 116} - Loading Pre-Trained Model\n",
      "2021-09-07 22:19:46,407 - /Users/meliksahturker/Desktop/Turkish-NLP-preprocessing-module/pp/morph_analyzer/model.py - INFO - 119} - Ready\n"
     ]
    }
   ],
   "source": [
    "from pp.morph_analyzer import MorphAnalyzer\n",
    "ma = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['üniversite+Noun+A3sg+Pnon+Nom',\n",
       " 'sınav+Noun+A3pl+P3sg+Dat',\n",
       " 'can+Noun+A3sg+Pnon+Ins',\n",
       " 'baş+Noun+A3sg+Pnon+Ins',\n",
       " 'çalış+Verb+Pos+Prog1+A3pl+Past']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ma.predict(\"üniversite sınavlarına canla başla çalışıyorlardı\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['şimdi+Adverb', 'baş+Noun+A3sg+Pnon+Abl', 'başla+Verb+Pos+Imp+A2sg']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ma.predict(\"şimdi baştan başla\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['koş+Verb+Pos+Imp+A2sg',\n",
       " 'da+Conj',\n",
       " 'top+Noun+A3sg+P3sg+Nom',\n",
       " 'at+Verb+Pos+Imp+A2sg']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ma.predict(\"koş da topu at\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['baba+Noun+A3sg+P1sg+Nom',\n",
       " 'ben+Pron+Pers+A1sg+Pnon+Dat',\n",
       " 'at+Noun+A3sg+Pnon+Nom',\n",
       " 'al+Verb+Pos+Past+A3sg']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ma.predict(\"babam bana at aldı\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['başar+Verb+Pos^DB+Verb+Able^DB+Noun+PastPart+A3pl+P1sg+Gen']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ma.predict(\"başarabildiklerimin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Named Entity Recognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\n",
    "from pp.named_entitiy_recognizer import NamedEntityRecognizer\n",
    "ner = NamedEntityRecognizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Ben', 'O'),\n",
       " ('Melikşah', 'PER'),\n",
       " (',', 'O'),\n",
       " ('28', 'O'),\n",
       " ('yaşındayım', 'O'),\n",
       " (',', 'O'),\n",
       " ('İstanbul', 'LOC'),\n",
       " (\"'\", 'O'),\n",
       " ('da', 'O'),\n",
       " ('ikamet', 'O'),\n",
       " ('ediyorum', 'O'),\n",
       " ('ve', 'O'),\n",
       " ('VNGRS', 'ORG'),\n",
       " ('AI', 'ORG'),\n",
       " ('Takımı', 'ORG'),\n",
       " (\"'\", 'O'),\n",
       " ('nda', 'O'),\n",
       " ('çalışıyorum', 'O'),\n",
       " ('.', 'O')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner.predict(\"Ben Melikşah, 28 yaşındayım, İstanbul'da ikamet ediyorum ve VNGRS AI Takımı'nda çalışıyorum.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalizer\n",
    "- Removes punctuations\n",
    "- Converts letters to lowercase\n",
    "- Converts numbers to word form\n",
    "- Removes accent marks\n",
    "- Deascification\n",
    "- Corrects typos using:\n",
    "    - pre-defined typos lexicon\n",
    "    - Levenshtein distance\n",
    "    - morphological analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-07 22:20:53,256 - /Users/meliksahturker/Desktop/Turkish-NLP-preprocessing-module/pp/morph_analyzer/model.py - INFO - 116} - Loading Pre-Trained Model\n",
      "2021-09-07 22:20:54,320 - /Users/meliksahturker/Desktop/Turkish-NLP-preprocessing-module/pp/morph_analyzer/model.py - INFO - 119} - Ready\n"
     ]
    }
   ],
   "source": [
    "from pp.normalizer import Normalizer\n",
    "n = Normalizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test',\n",
       " 'için',\n",
       " 'yazdığım',\n",
       " 'bir',\n",
       " 'cümledir',\n",
       " 'kasıtlı',\n",
       " 'yazım',\n",
       " 'hatası',\n",
       " 'ekliyorum',\n",
       " 'adım',\n",
       " 'melikşah',\n",
       " 'türker',\n",
       " 'yaşım',\n",
       " 'yirmisekiz']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"Test için yâzdığîm 1 cümledir. Kasitli yazişm hatasıı ekliyoruum. Adim meliksah turker, yasim 28.\"\n",
    "n.normalize(sentence.split(\" \"), normalize_via_levenshtein=True, deascify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['böyle', 'şey', 'görmedim', 'duymadım']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"boyle sey gormedim duymadim\"\n",
    "n.normalize(sentence.split(\" \"), deascify= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentence Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pp.sentence_splitter import SentenceSplitter\n",
    "ss = SentenceSplitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Av. Meryem Beşer, 3.5 yıldır süren dava ile ilgili dedi ki, \"Duruşma bitti, dava lehimize sonuçlandı.\"',\n",
       " 'Bu harika bir haber!']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss.split_sentences('Av. Meryem Beşer, 3.5 yıldır süren dava ile ilgili dedi ki, \"Duruşma bitti, dava lehimize sonuçlandı.\" Bu harika bir haber!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4. Murat, diğer yazım şekli ile IV. Murat, alkollü içecekleri halka yasaklamıştı.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss.split_sentences('4. Murat, diğer yazım şekli ile IV. Murat, alkollü içecekleri halka yasaklamıştı.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stopword Remover\n",
    "- Static: uses pre-defined lexicon of stopwords\n",
    "- Dynamic: detects stop-words regardless of language and context\n",
    "    - optional: can detect and drop rare-words (frequency of 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pp.stopword_remover import StopwordRemover\n",
    "sr = StopwordRemover()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"acaba bugün kahvaltıda kahve yerine çay mı içsem ya da neyse süt içeyim\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bugün', 'kahvaltıda', 'kahve', 'çay', 'içsem', 'süt', 'içeyim']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr.drop_stop_words(sentence.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-07 22:21:50,917 - root - INFO - 60} - Dynamically detected stopwords are: ama, aşı, çok, telefon, gelip\n"
     ]
    }
   ],
   "source": [
    "sentence = \"ben bugün aşı olacağım sonra da eve gelip telefon açacağım aşı nasıl etkiledi onu anlatırım telefon aşı olmak bu dönemde çok ama ama ama ama çok önemli\"\n",
    "sr.dynamically_detect_stop_words(sentence.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ama', 'aşı', 'çok', 'telefon', 'gelip']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr.dynamic_stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bizi', 'gereği', 've', 'ettiğini', 'nerede', 'yapıyor', 'onlara',\n",
       "       'bazen', 'ediliyor', 'ama'], dtype='<U11')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(sr.stop_words, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-07 22:21:50,935 - root - INFO - 67} - List of stop words is unified and updated.\n"
     ]
    }
   ],
   "source": [
    "sr.unify_stop_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'acaba',\n",
       " 'ama',\n",
       " 'ancak',\n",
       " 'arada',\n",
       " 'artık',\n",
       " 'asla',\n",
       " 'aslında',\n",
       " 'ayrıca',\n",
       " 'az',\n",
       " 'aşı']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr.stop_words[:11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Beşiktaş'tan   vapura binip Kadıköy'e geçtim. E-mail adresim turkermeliksah@hotmail.com. İnternette #boğaziçi hashtag'ini gördüm. türk hava yolları test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"Beşiktaş'tan\",\n",
       " 'vapura',\n",
       " 'binip',\n",
       " \"Kadıköy'e\",\n",
       " 'geçtim.',\n",
       " 'E-mail',\n",
       " 'adresim',\n",
       " 'turkermeliksah@hotmail.com.',\n",
       " 'İnternette',\n",
       " 'boğaziçi',\n",
       " \"hashtag'ini\",\n",
       " 'gördüm.',\n",
       " 'türk',\n",
       " 'hava',\n",
       " 'yolları',\n",
       " 'test')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pp.tokenizer import Tokenizer\n",
    "t = Tokenizer()\n",
    "t.tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import NLTKWordTokenizer, TweetTokenizer, WhitespaceTokenizer, WordPunctTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Beşiktaş'tan\",\n",
       " 'vapura',\n",
       " 'binip',\n",
       " \"Kadıköy'e\",\n",
       " 'geçtim',\n",
       " '.',\n",
       " 'E-mail',\n",
       " 'adresim',\n",
       " 'turkermeliksah@hotmail.com',\n",
       " '.',\n",
       " 'İnternette',\n",
       " '#boğaziçi',\n",
       " \"hashtag'ini\",\n",
       " 'gördüm',\n",
       " '.',\n",
       " 'türk',\n",
       " 'hava',\n",
       " 'yolları',\n",
       " 'test']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = TweetTokenizer()\n",
    "t.tokenize(sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
